{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/davydsadovskyy/GitBackedShit/crypto-prediction/notebooks\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from src.hopsworks_connections import pull_last_row, upload_data, pull_model, pull_data\n",
    "\n",
    "# Print the current working directory\n",
    "current_working_directory = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_working_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model from our Hopsworks model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 3.4.4 may not be compatible with the connected Hopsworks backend version 3.7.1. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (3.7) by running 'pip install hopsworks==3.7.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/582805\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Downloading model artifact (0 dirs, 1 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'random_forest_ohlc' # this one predicts tmw_1_0_percent_increase_binary\n",
    "\n",
    "# ***** later implement code that checks the latest model version and pulls that one\n",
    "# def pull_model(model_name, model_version):\n",
    "model = pull_model(MODEL_NAME, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the latest day of ethereum data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 3.4.4 may not be compatible with the connected Hopsworks backend version 3.7.1. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (3.7) by running 'pip install hopsworks==3.7.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/582805\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Feature view already existed. Skip creation.\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (1.57s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>volume_eth</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>tmw_avg_high_close</th>\n",
       "      <th>tmw_percent_increase</th>\n",
       "      <th>...</th>\n",
       "      <th>october</th>\n",
       "      <th>november</th>\n",
       "      <th>december</th>\n",
       "      <th>monday</th>\n",
       "      <th>tuesday</th>\n",
       "      <th>wednesday</th>\n",
       "      <th>thursday</th>\n",
       "      <th>friday</th>\n",
       "      <th>saturday</th>\n",
       "      <th>sunday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-21 00:00:00+00:00</td>\n",
       "      <td>3142.949775</td>\n",
       "      <td>3170.679379</td>\n",
       "      <td>3137.747159</td>\n",
       "      <td>3147.137754</td>\n",
       "      <td>9.264213e+09</td>\n",
       "      <td>2.940255e+06</td>\n",
       "      <td>3.778353e+11</td>\n",
       "      <td>3214.065786</td>\n",
       "      <td>0.020823</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date         open         high          low  \\\n",
       "0 2024-04-21 00:00:00+00:00  3142.949775  3170.679379  3137.747159   \n",
       "\n",
       "         close        volume    volume_eth    market_cap  tmw_avg_high_close  \\\n",
       "0  3147.137754  9.264213e+09  2.940255e+06  3.778353e+11         3214.065786   \n",
       "\n",
       "   tmw_percent_increase  ...  october  november  december  monday  tuesday  \\\n",
       "0              0.020823  ...        0         0         0       0        0   \n",
       "\n",
       "   wednesday  thursday  friday  saturday  sunday  \n",
       "0          0         0       0         0       1  \n",
       "\n",
       "[1 rows x 111 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth_yesterday = pull_last_row('eth_ohlc_transformed', 2, 'eth_ohlc_transformed_view', 2)\n",
    "\n",
    "eth_yesterday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define predictors, the input data points, and get a prediction for tmw_1_0_percent_increase_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ema_2</th>\n",
       "      <th>rsi_2</th>\n",
       "      <th>sma_2</th>\n",
       "      <th>last_2_day_1_0_percent_increase_count</th>\n",
       "      <th>last_2_day_1_25_percent_increase_count</th>\n",
       "      <th>last_2_day_1_5_percent_increase_count</th>\n",
       "      <th>last_2_day_1_75_percent_increase_count</th>\n",
       "      <th>last_2_day_2_0_percent_increase_count</th>\n",
       "      <th>last_2_day_2_25_percent_increase_count</th>\n",
       "      <th>last_2_day_2_5_percent_increase_count</th>\n",
       "      <th>...</th>\n",
       "      <th>october</th>\n",
       "      <th>november</th>\n",
       "      <th>december</th>\n",
       "      <th>monday</th>\n",
       "      <th>tuesday</th>\n",
       "      <th>wednesday</th>\n",
       "      <th>thursday</th>\n",
       "      <th>friday</th>\n",
       "      <th>saturday</th>\n",
       "      <th>sunday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.002061</td>\n",
       "      <td>75.270475</td>\n",
       "      <td>0.998752</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ema_2      rsi_2     sma_2  last_2_day_1_0_percent_increase_count  \\\n",
       "0  1.002061  75.270475  0.998752                                    1.0   \n",
       "\n",
       "   last_2_day_1_25_percent_increase_count  \\\n",
       "0                                     1.0   \n",
       "\n",
       "   last_2_day_1_5_percent_increase_count  \\\n",
       "0                                    1.0   \n",
       "\n",
       "   last_2_day_1_75_percent_increase_count  \\\n",
       "0                                     1.0   \n",
       "\n",
       "   last_2_day_2_0_percent_increase_count  \\\n",
       "0                                    1.0   \n",
       "\n",
       "   last_2_day_2_25_percent_increase_count  \\\n",
       "0                                     1.0   \n",
       "\n",
       "   last_2_day_2_5_percent_increase_count  ...  october  november  december  \\\n",
       "0                                    0.0  ...        0         0         0   \n",
       "\n",
       "   monday  tuesday  wednesday  thursday  friday  saturday  sunday  \n",
       "0       0        0          0         0       0         0       1  \n",
       "\n",
       "[1 rows x 91 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = []\n",
    "periods = [2, 5, 10, 25, 50, 100]\n",
    "percent_increase_counts = ['1_0', '1_25', '1_5', '1_75', '2_0', '2_25', '2_5', '2_75', '3_0']\n",
    "for period in periods:\n",
    "    for indicator in ['ema', 'rsi', 'sma']:\n",
    "        predictors.append(f'{indicator}_{period}')\n",
    "    for percent in percent_increase_counts:\n",
    "        predictors.append(f'last_{period}_day_{percent}_percent_increase_count')\n",
    "months = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "predictors.extend(months)\n",
    "weekdays = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "predictors.extend(weekdays)\n",
    "\n",
    "x0 = eth_yesterday[predictors].iloc[-1:]\n",
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(x0)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "Name: pred_tmw_1_0_percent_increase_binary, dtype: Int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = int(prediction[0])\n",
    "eth_yesterday.at[eth_yesterday.index[-1], 'pred_tmw_1_0_percent_increase_binary'] = pred\n",
    "\n",
    "eth_yesterday['pred_tmw_1_0_percent_increase_binary'] = eth_yesterday['pred_tmw_1_0_percent_increase_binary'].astype('Int64')\n",
    "\n",
    "eth_yesterday['pred_tmw_1_0_percent_increase_binary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload this prediction to a separate predictions feature group in Hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 3.4.4 may not be compatible with the connected Hopsworks backend version 3.7.1. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (3.7) by running 'pip install hopsworks==3.7.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/582805\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/582805/fs/578628/fg/741743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 1/1 | Elapsed Time: 00:05 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: eth_ohlc_predictions_2_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/582805/jobs/named/eth_ohlc_predictions_2_offline_fg_materialization/executions\n"
     ]
    }
   ],
   "source": [
    "upload_data(eth_yesterday, 'eth_ohlc_predictions', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 3.4.4 may not be compatible with the connected Hopsworks backend version 3.7.1. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (3.7) by running 'pip install hopsworks==3.7.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/582805\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/582805/fs/578628/fv/eth_ohlc_predictions_view/version/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Could not establish connection to ArrowFlight Server. (Flight returned timeout error, with message: Deadline Exceeded) Will fall back to hive/spark for this session. If the error persists, you can disable using ArrowFlight by changing the cluster configuration (set 'enable_flyingduck'='false').\n",
      "DeprecationWarning: ssl.PROTOCOL_TLS is deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hive (1.39s) \n"
     ]
    },
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/582805/featurestores/578628/featureview/eth_ohlc_predictions_view/version/9/trainingdatasets/version/1/statistics). Server response: \nHTTP code: 400, HTTP reason: Bad Request, body: b'Non-standard token \\'NaN\\': enable JsonParser.Feature.ALLOW_NON_NUMERIC_NUMBERS to allow\\n at [Source: (org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$UnCloseableInputStream); line: 1, column: 379] (through reference chain: io.hops.hopsworks.common.featurestore.statistics.StatisticsDTO[\"featureDescriptiveStatistics\"]->java.util.ArrayList[0])', error code: , error msg: , user msg: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pull_last_row('eth_ohlc_predictions', 2, 'eth_ohlc_predictions_view', 5)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpull_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meth_ohlc_predictions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meth_ohlc_predictions_view\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GitBackedShit/crypto-prediction/src/hopsworks_connections.py:52\u001b[0m, in \u001b[0;36mpull_data\u001b[0;34m(feature_group_name, feature_group_version, feature_view_name, feature_view_version)\u001b[0m\n\u001b[1;32m     45\u001b[0m feature_view \u001b[38;5;241m=\u001b[39m feature_store\u001b[38;5;241m.\u001b[39mget_feature_view(\n\u001b[1;32m     46\u001b[0m     name\u001b[38;5;241m=\u001b[39mfeature_view_name,\n\u001b[1;32m     47\u001b[0m     version\u001b[38;5;241m=\u001b[39mfeature_view_version\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# even when the second object is defined, it is still noneType... In hopsworks docs tho,\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# they define like this: feature_df, label_df\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m data, _ \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransformed Ethereum OHLC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     54\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# data = feature_view.create_training_data()\u001b[39;00m\n",
      "File \u001b[0;32m~/GitBackedShit/crypto-prediction/venv_crypto_prediction/lib/python3.10/site-packages/hsfs/usage.py:208\u001b[0m, in \u001b[0;36mmethod_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    207\u001b[0m     exception \u001b[38;5;241m=\u001b[39m e\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/GitBackedShit/crypto-prediction/venv_crypto_prediction/lib/python3.10/site-packages/hsfs/usage.py:204\u001b[0m, in \u001b[0;36mmethod_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# Call the original method\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/GitBackedShit/crypto-prediction/venv_crypto_prediction/lib/python3.10/site-packages/hsfs/feature_view.py:2219\u001b[0m, in \u001b[0;36mFeatureView.training_data\u001b[0;34m(self, start_time, end_time, description, extra_filter, statistics_config, read_options, spine, primary_keys, event_time, training_helper_columns)\u001b[0m\n\u001b[1;32m   2106\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2107\u001b[0m \u001b[38;5;124;03mCreate the metadata for a training dataset and get the corresponding training data from the offline feature store.\u001b[39;00m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;124;03mThis returns the training data in memory and does not materialise data in storage.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[38;5;124;03m    (X, y): Tuple of dataframe of features and labels. If there are no labels, y returns `None`.\u001b[39;00m\n\u001b[1;32m   2203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2204\u001b[0m td \u001b[38;5;241m=\u001b[39m training_dataset\u001b[38;5;241m.\u001b[39mTrainingDataset(\n\u001b[1;32m   2205\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   2206\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2217\u001b[0m     extra_filter\u001b[38;5;241m=\u001b[39mextra_filter,\n\u001b[1;32m   2218\u001b[0m )\n\u001b[0;32m-> 2219\u001b[0m td, df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_view_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_training_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_dataset_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprimary_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprimary_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevent_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevent_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_helper_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_helper_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2227\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2228\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2229\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented version to `\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(td\u001b[38;5;241m.\u001b[39mversion),\n\u001b[1;32m   2230\u001b[0m     util\u001b[38;5;241m.\u001b[39mVersionWarning,\n\u001b[1;32m   2231\u001b[0m )\n\u001b[1;32m   2232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/GitBackedShit/crypto-prediction/venv_crypto_prediction/lib/python3.10/site-packages/hsfs/core/feature_view_engine.py:349\u001b[0m, in \u001b[0;36mFeatureViewEngine.get_training_data\u001b[0;34m(self, feature_view_obj, read_options, splits, training_dataset_obj, training_dataset_version, spine, primary_keys, event_time, training_helper_columns)\u001b[0m\n\u001b[1;32m    334\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_batch_query(\n\u001b[1;32m    335\u001b[0m         feature_view_obj,\n\u001b[1;32m    336\u001b[0m         training_dataset_version\u001b[38;5;241m=\u001b[39mtd_updated\u001b[38;5;241m.\u001b[39mversion,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    344\u001b[0m         spine\u001b[38;5;241m=\u001b[39mspine,\n\u001b[1;32m    345\u001b[0m     )\n\u001b[1;32m    346\u001b[0m     split_df \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mget_instance()\u001b[38;5;241m.\u001b[39mget_training_data(\n\u001b[1;32m    347\u001b[0m         td_updated, feature_view_obj, query, read_options\n\u001b[1;32m    348\u001b[0m     )\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_training_dataset_statistics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_view_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtd_updated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_df\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# split df into features and labels df\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m td_updated\u001b[38;5;241m.\u001b[39msplits:\n",
      "File \u001b[0;32m~/GitBackedShit/crypto-prediction/venv_crypto_prediction/lib/python3.10/site-packages/hsfs/core/feature_view_engine.py:633\u001b[0m, in \u001b[0;36mFeatureViewEngine.compute_training_dataset_statistics\u001b[0;34m(self, feature_view_obj, training_dataset_obj, td_df)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_statistics_engine\u001b[38;5;241m.\u001b[39mcompute_and_save_split_statistics(\n\u001b[1;32m    628\u001b[0m         training_dataset_obj,\n\u001b[1;32m    629\u001b[0m         feature_dataframes\u001b[38;5;241m=\u001b[39mtd_df,\n\u001b[1;32m    630\u001b[0m         feature_view_obj\u001b[38;5;241m=\u001b[39mfeature_view_obj,\n\u001b[1;32m    631\u001b[0m     )\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statistics_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_and_save_statistics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_dataset_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtd_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_view_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_view_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GitBackedShit/crypto-prediction/venv_crypto_prediction/lib/python3.10/site-packages/hsfs/core/statistics_engine.py:81\u001b[0m, in \u001b[0;36mStatisticsEngine.compute_and_save_statistics\u001b[0;34m(self, metadata_instance, feature_dataframe, feature_group_commit_id, feature_view_obj)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m desc_stats:\n\u001b[1;32m     76\u001b[0m         stats \u001b[38;5;241m=\u001b[39m statistics\u001b[38;5;241m.\u001b[39mStatistics(\n\u001b[1;32m     77\u001b[0m             computation_time\u001b[38;5;241m=\u001b[39mcomputation_time,\n\u001b[1;32m     78\u001b[0m             feature_descriptive_statistics\u001b[38;5;241m=\u001b[39mdesc_stats,\n\u001b[1;32m     79\u001b[0m             window_end_commit_time\u001b[38;5;241m=\u001b[39mfeature_group_commit_id,\n\u001b[1;32m     80\u001b[0m         )\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_statistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_view_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# Python engine\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mget_instance()\u001b[38;5;241m.\u001b[39mprofile_by_spark(metadata_instance)\n",
      "File \u001b[0;32m~/GitBackedShit/crypto-prediction/venv_crypto_prediction/lib/python3.10/site-packages/hsfs/core/statistics_engine.py:424\u001b[0m, in \u001b[0;36mStatisticsEngine._save_statistics\u001b[0;34m(self, stats, metadata_instance, feature_view_obj)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save_statistics\u001b[39m(\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28mself\u001b[39m, stats, metadata_instance, feature_view_obj\n\u001b[1;32m    421\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m statistics\u001b[38;5;241m.\u001b[39mStatistics:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# metadata_instance can be feature group or training dataset\u001b[39;00m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_view_obj:\n\u001b[0;32m--> 424\u001b[0m         stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statistics_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature_view_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtraining_dataset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    430\u001b[0m         stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_statistics_api\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m    431\u001b[0m             metadata_instance, stats\u001b[38;5;241m=\u001b[39mstats, training_dataset_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    432\u001b[0m         )\n",
      "File \u001b[0;32m~/GitBackedShit/crypto-prediction/venv_crypto_prediction/lib/python3.10/site-packages/hsfs/core/statistics_api.py:43\u001b[0m, in \u001b[0;36mStatisticsApi.post\u001b[0;34m(self, metadata_instance, stats, training_dataset_version)\u001b[0m\n\u001b[1;32m     39\u001b[0m path_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_path(metadata_instance, training_dataset_version)\n\u001b[1;32m     41\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     42\u001b[0m stats \u001b[38;5;241m=\u001b[39m statistics\u001b[38;5;241m.\u001b[39mStatistics\u001b[38;5;241m.\u001b[39mfrom_response_json(\n\u001b[0;32m---> 43\u001b[0m     \u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_single_stats(stats)\n",
      "File \u001b[0;32m~/GitBackedShit/crypto-prediction/venv_crypto_prediction/lib/python3.10/site-packages/hsfs/decorators.py:35\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst\u001b[38;5;241m.\u001b[39m_connected:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GitBackedShit/crypto-prediction/venv_crypto_prediction/lib/python3.10/site-packages/hsfs/client/base.py:179\u001b[0m, in \u001b[0;36mClient._send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files)\u001b[0m\n\u001b[1;32m    176\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39msend(prepped, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRestAPIError(url, response)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/582805/featurestores/578628/featureview/eth_ohlc_predictions_view/version/9/trainingdatasets/version/1/statistics). Server response: \nHTTP code: 400, HTTP reason: Bad Request, body: b'Non-standard token \\'NaN\\': enable JsonParser.Feature.ALLOW_NON_NUMERIC_NUMBERS to allow\\n at [Source: (org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$UnCloseableInputStream); line: 1, column: 379] (through reference chain: io.hops.hopsworks.common.featurestore.statistics.StatisticsDTO[\"featureDescriptiveStatistics\"]->java.util.ArrayList[0])', error code: , error msg: , user msg: "
     ]
    }
   ],
   "source": [
    "# pull_last_row('eth_ohlc_predictions', 2, 'eth_ohlc_predictions_view', 5)\n",
    "# pull_data('eth_ohlc_predictions', 2, 'eth_ohlc_predictions_view', 9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_crypto_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
